# Домашнее задание: Сегментация с предобученным UNet

## Задача

Обучить модель семантической сегментации на датасете CamVid, используя предобученный UNet из библиотеки `segmentation_models_pytorch`.

## Требования

**Целевая метрика:** Mean IoU (mIoU) >= 0.7 на валидационном датасете.

## Датасет

- **CamVid** - датасет для семантической сегментации дорожных сцен
- **Классы:** 12 классов (Sky, Building, Column-Pole, Road, Sidewalk, Tree, Sign-Symbol, Fence, Car, Pedestrian, Bicyclist, Void)
- **Разделы:** train (~367 изображений), val (~101 изображение), test (~233 изображения)

## Базовый ноутбук

Базовый ноутбук `baseline.ipynb` содержит:
- Загрузку предобученного UNet с энкодером ResNet34
- Базовые аугментации из albumentations
- Обучение с OneCycleLR scheduler
- Вычисление метрик IoU

## Советы для достижения mIoU >= 0.7

### 1. Архитектура модели
- Попробуйте более мощные энкодеры: `resnet50`, `efficientnet-b3`
- Более глубокие модели обычно дают лучшее качество

### 2. Аугментации
- Добавьте `ElasticTransform`, `CoarseDropout` для разнообразия
- Не делайте аугментации слишком сильными

### 3. Гиперпараметры
- Подберите learning rate (попробуйте 1e-3, 5e-4)
- Увеличьте batch size если позволяет память
- Используйте AdamW с weight_decay=0.0001

### 4. Разрешение и обучение
- Увеличьте размер изображений до 384x384 или 512x512
- Используйте Focal Loss вместо CrossEntropy для несбалансированных классов
- Включите mixed precision: `precision=16` в Trainer

### 5. Анализ и улучшение
- Следите за IoU по каждому классу отдельно
- Визуализируйте ошибки на валидации
- Используйте Test Time Augmentation (TTA) для финальных предсказаний

## Критерии оценки

- **mIoU >= 0.7** - минимальное требование
- Оценивается качество на валидационном датасете
- Важно не только достичь целевой метрики, но и понять какие техники помогли

## Полезные ссылки

- [segmentation_models_pytorch документация](https://github.com/qubvel/segmentation_models.pytorch)
- [albumentations документация](https://albumentations.ai/)
