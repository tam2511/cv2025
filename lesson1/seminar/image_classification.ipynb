{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Пайплайн обучения классификационной модели\n",
        "\n",
        "В этом ноутбуке мы построим полный пайплайн обучения модели классификации изображений на датасете ImageNet Tiny.\n",
        "\n",
        "Мы пройдем следующие шаги:\n",
        "1. Создание и загрузка датасета\n",
        "2. Предобработка и аугментация данных\n",
        "3. Архитектура модели\n",
        "4. Цикл обучения\n",
        "5. Оценка и визуализация\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Шаг 1: Создание датасета\n",
        "\n",
        "Начнем с создания и загрузки датасета ImageNet Tiny.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = './data/imagenet_tiny'\n",
        "\n",
        "print(\"Setting up ImageNet Tiny dataset...\")\n",
        "print(f\"Data directory: {data_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(data_dir, 'train'),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "val_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(data_dir, 'val'),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Classes: {train_dataset.classes[:10]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_samples(dataset, num_samples=8):\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        image, label = dataset[idx]\n",
        "        img = image.permute(1, 2, 0).numpy()\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'Class: {dataset.classes[label]}')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_samples(train_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Шаг 2: Архитектура модели\n",
        "\n",
        "Создадим простую сверточную нейронную сеть для классификации изображений.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=200):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        \n",
        "        x = x.view(-1, 512 * 14 * 14)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = len(train_dataset.classes)\n",
        "model = SimpleCNN(num_classes=num_classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model created with {num_classes} classes\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "sample_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "output = model(sample_input)\n",
        "print(f\"Input shape: {sample_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Шаг 3: Lightning модуль\n",
        "\n",
        "Создадим Lightning модуль с определением модели, loss функции, метрик и оптимизатора.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torchmetrics import Accuracy\n",
        "import torch.optim as optim\n",
        "\n",
        "class ClassificationModule(pl.LightningModule):\n",
        "    def __init__(self, num_classes=200, learning_rate=0.001, steps_per_epoch=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.model = SimpleCNN(num_classes=num_classes)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.train_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        self.val_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        \n",
        "        self.learning_rate = learning_rate\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        \n",
        "        self.save_hyperparameters()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        \n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        self.train_accuracy(preds, labels)\n",
        "        \n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_acc', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        \n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        self.val_accuracy(preds, labels)\n",
        "        \n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_acc', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        self.log('train_acc_epoch', self.train_accuracy.compute())\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log('val_acc_epoch', self.val_accuracy.compute())\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        \n",
        "        if self.steps_per_epoch is not None:\n",
        "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "                optimizer,\n",
        "                max_lr=self.learning_rate,\n",
        "                epochs=self.trainer.max_epochs,\n",
        "                steps_per_epoch=self.steps_per_epoch\n",
        "            )\n",
        "            \n",
        "            return {\n",
        "                'optimizer': optimizer,\n",
        "                'lr_scheduler': {\n",
        "                    'scheduler': scheduler,\n",
        "                    'interval': 'step'\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "steps_per_epoch = len(train_loader)\n",
        "lightning_model = ClassificationModule(\n",
        "    num_classes=num_classes, \n",
        "    learning_rate=0.001,\n",
        "    steps_per_epoch=steps_per_epoch\n",
        ")\n",
        "\n",
        "print(\"Lightning module created successfully\")\n",
        "print(f\"Steps per epoch: {steps_per_epoch}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Шаг 4: Обучение модели\n",
        "\n",
        "Запустим обучение модели с помощью Lightning Trainer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import Callback\n",
        "\n",
        "class PrintMetricsCallback(Callback):\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        metrics = trainer.callback_metrics\n",
        "        epoch = trainer.current_epoch\n",
        "        \n",
        "        train_loss = metrics.get('train_loss_epoch', 0)\n",
        "        train_acc = metrics.get('train_acc_epoch', 0)\n",
        "        \n",
        "        print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        metrics = trainer.callback_metrics\n",
        "        epoch = trainer.current_epoch\n",
        "        \n",
        "        val_loss = metrics.get('val_loss', 0)\n",
        "        val_acc = metrics.get('val_acc_epoch', 0)\n",
        "        \n",
        "        print(f\"Epoch {epoch} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        "    accelerator='auto',\n",
        "    devices='auto',\n",
        "    callbacks=[PrintMetricsCallback()],\n",
        "    enable_progress_bar=True,\n",
        "    logger=False\n",
        ")\n",
        "\n",
        "trainer.fit(lightning_model, train_loader, val_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Шаг 5: Модели из timm\n",
        "\n",
        "Изучим различные предобученные модели из библиотеки timm и сравним их по количеству параметров и скорости инференса.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import timm\n",
        "import time\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def measure_inference_time(model, input_shape, num_iterations=100, device='cuda'):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    dummy_input = torch.randn(input_shape).to(device)\n",
        "    \n",
        "    torch.cuda.synchronize() if device == 'cuda' else None\n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_iterations):\n",
        "            _ = model(dummy_input)\n",
        "    \n",
        "    torch.cuda.synchronize() if device == 'cuda' else None\n",
        "    end_time = time.time()\n",
        "    \n",
        "    avg_time = (end_time - start_time) / num_iterations\n",
        "    return avg_time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names = [\n",
        "    'resnet18',\n",
        "    'resnet50',\n",
        "    'efficientnet_b0',\n",
        "    'efficientnet_b3',\n",
        "    'vit_base_patch16_224',\n",
        "    'convnext_tiny'\n",
        "]\n",
        "\n",
        "num_classes = len(train_dataset.classes) if 'train_dataset' in globals() else 200\n",
        "input_shape = (1, 3, 224, 224)\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name in model_names:\n",
        "    try:\n",
        "        print(f\"\\nLoading {model_name}...\")\n",
        "        model = timm.create_model(\n",
        "            model_name,\n",
        "            pretrained=False,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "        \n",
        "        num_params = count_parameters(model)\n",
        "        print(f\"Parameters: {num_params:,}\")\n",
        "        \n",
        "        inference_time = measure_inference_time(model, input_shape, num_iterations=50, device=device)\n",
        "        print(f\"Inference time: {inference_time*1000:.2f} ms\")\n",
        "        \n",
        "        results.append({\n",
        "            'model': model_name,\n",
        "            'parameters': num_params,\n",
        "            'inference_time_ms': inference_time * 1000\n",
        "        })\n",
        "        \n",
        "        del model\n",
        "        torch.cuda.empty_cache() if device == 'cuda' else None\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {model_name}: {e}\")\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Comparison of timm models:\")\n",
        "print(\"=\"*60)\n",
        "print(df_results.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax1.barh(df_results['model'], df_results['parameters'] / 1e6)\n",
        "ax1.set_xlabel('Parameters (Millions)')\n",
        "ax1.set_title('Number of Parameters')\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "\n",
        "ax2.barh(df_results['model'], df_results['inference_time_ms'])\n",
        "ax2.set_xlabel('Inference Time (ms)')\n",
        "ax2.set_title('Inference Speed')\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Шаг 6: Обучение модели из timm\n",
        "\n",
        "Обучим модель ConvNeXt Tiny из timm на нашем датасете.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimmClassificationModule(pl.LightningModule):\n",
        "    def __init__(self, model_name='convnext_tiny', num_classes=200, learning_rate=0.001, steps_per_epoch=None, pretrained=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.model = timm.create_model(\n",
        "            model_name,\n",
        "            pretrained=pretrained,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.train_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        self.val_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        \n",
        "        self.learning_rate = learning_rate\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        \n",
        "        self.save_hyperparameters()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        \n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        self.train_accuracy(preds, labels)\n",
        "        \n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_acc', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        \n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        self.val_accuracy(preds, labels)\n",
        "        \n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_acc', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def training_epoch_end(self, outputs):\n",
        "        self.log('train_acc_epoch', self.train_accuracy.compute())\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log('val_acc_epoch', self.val_accuracy.compute())\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        \n",
        "        if self.steps_per_epoch is not None:\n",
        "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "                optimizer,\n",
        "                max_lr=self.learning_rate,\n",
        "                epochs=self.trainer.max_epochs,\n",
        "                steps_per_epoch=self.steps_per_epoch\n",
        "            )\n",
        "            \n",
        "            return {\n",
        "                'optimizer': optimizer,\n",
        "                'lr_scheduler': {\n",
        "                    'scheduler': scheduler,\n",
        "                    'interval': 'step'\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = len(train_dataset.classes)\n",
        "steps_per_epoch = len(train_loader)\n",
        "\n",
        "timm_model = TimmClassificationModule(\n",
        "    model_name='convnext_tiny',\n",
        "    num_classes=num_classes,\n",
        "    learning_rate=0.001,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "print(\"Timm model module created successfully\")\n",
        "print(f\"Model: convnext_tiny\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Steps per epoch: {steps_per_epoch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_timm = Trainer(\n",
        "    max_epochs=10,\n",
        "    accelerator='auto',\n",
        "    devices='auto',\n",
        "    callbacks=[PrintMetricsCallback()],\n",
        "    enable_progress_bar=True,\n",
        "    logger=False\n",
        ")\n",
        "\n",
        "trainer_timm.fit(timm_model, train_loader, val_loader)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
